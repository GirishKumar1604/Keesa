# build_faiss.py
import faiss
import pandas as pd
import numpy as np
import pickle
from sklearn.feature_extraction.text import TfidfVectorizer
import os

# âœ… File paths
MERCHANT_FILE = os.path.join(os.path.dirname(__file__), "../data/merchant.csv")
VECTORIZER_PATH = os.path.join(os.path.dirname(__file__), "vectorizer.pkl")
INDEX_PATH = os.path.join(os.path.dirname(__file__), "faiss.index")

# âœ… Load merchant names
print("ðŸ“¥ Loading merchants...")
df = pd.read_csv(MERCHANT_FILE)
merchant_names = df['merchant_name'].fillna("").str.lower().tolist()
print(f"âœ… Loaded {len(merchant_names)} merchants.")

# âœ… Create TF-IDF embeddings
print("ðŸ§  Generating TF-IDF embeddings...")
vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(merchant_names)

# âœ… Convert to dense numpy array
embeddings = X.toarray().astype("float32")

# âœ… Save vectorizer
with open(VECTORIZER_PATH, "wb") as f:
    pickle.dump(vectorizer, f)
print(f"âœ… Vectorizer saved to {VECTORIZER_PATH}")

# âœ… Build FAISS index
index = faiss.IndexFlatL2(embeddings.shape[1])
index.add(embeddings)
faiss.write_index(index, INDEX_PATH)
print(f"âœ… FAISS index saved to {INDEX_PATH}")
